{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love the boy .',\n",
       " 'I love the dog .',\n",
       " 'They love the dog .',\n",
       " 'They talk to the girl .',\n",
       " 'They talk to the dog .',\n",
       " 'I talk to the mother .']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def clean_sentence(sentence): \n",
    "    '''\n",
    "    Separate out punctuation into their own \"words'\n",
    "    arg:\n",
    "        sentence (str): Sentence as a string (should not include new line character).\n",
    "    return:\n",
    "        cleaned_sentence (str): Sentence with all punctuation separated by whitespace. \n",
    "    '''\n",
    "    chars = []\n",
    "    for i in range(len(sentence)): \n",
    "        if sentence[i] in string.punctuation: \n",
    "            # If there's whitespace before the punctuation\n",
    "            if sentence[i-1]!=\" \":\n",
    "                char = \" {}\".format(sentence[i])\n",
    "            # If we're not at the end of the sentence and there's whitespace after the punctuation. \n",
    "            if i!=len(sentence)-1 and sentence[i+1]!=\" \":\n",
    "                char = \"{} \".format(char)\n",
    "            chars.append(char)\n",
    "        else:\n",
    "            chars.append(sentence[i])\n",
    "        cleaned_sentence = ''.join(chars)    \n",
    "    return cleaned_sentence\n",
    "\n",
    "def read_text_into_array(filename):\n",
    "    '''\n",
    "    Read text file into array (removing new line character).\n",
    "    arg:\n",
    "        filename (str): Filename as string.\n",
    "    return:\n",
    "        corpus_stripped (list): List of stripped sentences (no new line character). \n",
    "    '''\n",
    "    with open(filename, 'r') as f:\n",
    "        corpus_raw = f.readlines()\n",
    "        # Strip the new line character from each line.     \n",
    "        corpus_stripped = [line.strip() for line in corpus_raw]\n",
    "        return corpus_stripped\n",
    "\n",
    "corpus = read_text_into_array(\"corpus.txt\")\n",
    "corpus_clean = []\n",
    "for sentence in corpus:\n",
    "    corpus_clean.append(clean_sentence(sentence))\n",
    "corpus_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'I': 3.0,\n",
       "             'love': 3.0,\n",
       "             'the': 6.0,\n",
       "             'boy': 1.0,\n",
       "             '.': 6.0,\n",
       "             'dog': 3.0,\n",
       "             'They': 3.0,\n",
       "             'talk': 3.0,\n",
       "             'to': 3.0,\n",
       "             'girl': 1.0,\n",
       "             'mother': 1.0})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unigram_count(corpus_clean):\n",
    "    \"\"\"\n",
    "    Counts unigrams in a corpus.\n",
    "    \"\"\"\n",
    "    word_count = defaultdict(float)\n",
    "    total_words = 0\n",
    "\n",
    "    for sentence in corpus_clean:\n",
    "        total_words += len(sentence.split())\n",
    "        for word in sentence.split():\n",
    "            word_count[word] += 1\n",
    "    return word_count\n",
    "\n",
    "count_dict = unigram_count(corpus_clean)\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'I': 0.09090909090909091,\n",
       "             'love': 0.09090909090909091,\n",
       "             'the': 0.18181818181818182,\n",
       "             'boy': 0.030303030303030304,\n",
       "             '.': 0.18181818181818182,\n",
       "             'dog': 0.09090909090909091,\n",
       "             'They': 0.09090909090909091,\n",
       "             'talk': 0.09090909090909091,\n",
       "             'to': 0.09090909090909091,\n",
       "             'girl': 0.030303030303030304,\n",
       "             'mother': 0.030303030303030304})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unigram_prob(count_dict):\n",
    "    \"\"\"\n",
    "    Calculates unigram probabilities.\n",
    "    \"\"\"\n",
    "    prob_dict = defaultdict(float)\n",
    "    total_words = sum(count_dict.values())\n",
    "    for word, count in count_dict.items():\n",
    "        word_prob = count / total_words\n",
    "        prob_dict[word] = word_prob\n",
    "    return prob_dict\n",
    "\n",
    "unigram_prob_dict = unigram_prob(count_dict)\n",
    "unigram_prob_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of each sentence in the corpus using a unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.27895097412207e-06%: I love the boy .\n",
      "2.483685292236621e-05%: I love the dog .\n",
      "2.483685292236621e-05%: They love the dog .\n",
      "7.526319067383701e-07%: They talk to the girl .\n",
      "2.25789572021511e-06%: They talk to the dog .\n",
      "7.526319067383701e-07%: I talk to the mother .\n"
     ]
    }
   ],
   "source": [
    "#Â Multiply the probability of each word in the sentence\n",
    "for sentence in corpus_clean:\n",
    "    sentence_prob = []\n",
    "    for word in sentence.split():\n",
    "        sentence_prob.append(unigram_prob_dict[word])\n",
    "    print(f'{np.prod(sentence_prob)}%: {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007407407407407406 - <s> I love the boy . </s>\n",
      "0.02222222222222222 - <s> I love the dog . </s>\n",
      "0.01111111111111111 - <s> They love the dog . </s>\n",
      "0.007407407407407406 - <s> They talk to the girl . </s>\n",
      "0.02222222222222222 - <s> They talk to the dog . </s>\n",
      "0.003703703703703703 - <s> I talk to the mother . </s>\n"
     ]
    }
   ],
   "source": [
    "def get_bigrams(corpus_clean):\n",
    "    \"\"\"\n",
    "    Extract bigrams from corpus.\n",
    "    \"\"\"\n",
    "    bigrams = []\n",
    "    for line in corpus_clean:\n",
    "        line = line.split()\n",
    "        for i in range(len(line)-1):\n",
    "            bigrams.append(line[i:i+2])\n",
    "    return bigrams\n",
    "\n",
    "def ngram_count(ngrams):\n",
    "    \"\"\"\n",
    "    Count n-grams in a corpus\n",
    "    \"\"\"\n",
    "    ngram_count_dict = defaultdict(float)\n",
    "    for ngram in ngrams:\n",
    "        ngram_count_dict[tuple(ngram)] += 1 # Tuples are immutable\n",
    "    return ngram_count_dict\n",
    "\n",
    "def bigram_prob(bigram_count_dict, count_dict):\n",
    "    \"\"\"\n",
    "    Calculate bigram probabilities\n",
    "    \"\"\"\n",
    "    bigram_prob_dict = defaultdict(float)\n",
    "    for bigram, count in bigram_count_dict.items():\n",
    "        # Dive the bigram count by the count for the single word that comes before it\n",
    "        bigram_prob = count / count_dict[bigram[0]]\n",
    "        bigram_prob_dict[bigram] = bigram_prob\n",
    "    return bigram_prob_dict\n",
    "\n",
    "# Let's add some \"start\" and \"end\" characters and recompute the counts\n",
    "corpus_mod= [\"<s> {} </s>\".format(line) for line in corpus_clean]\n",
    "count_dict = unigram_count(corpus_mod)\n",
    "unigram_prob_dict = unigram_prob(count_dict)\n",
    "bigrams = get_bigrams(corpus_mod)\n",
    "bigram_count_dict = ngram_count(bigrams)\n",
    "bigram_prob_dict = bigram_prob(bigram_count_dict, count_dict)\n",
    "\n",
    "for line in corpus_mod:\n",
    "    line_split = line.split()\n",
    "    # Start with the probability of <s> alone to begin with\n",
    "    line_probs = [unigram_prob_dict[line_split[0]]]\n",
    "    for i in range(len(line_split) - 1):\n",
    "        line_probs.append(bigram_prob_dict[tuple(line_split[i:i+2])])\n",
    "    print(f'{np.prod(line_probs)} - {line}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111 - ['<s>', 'I', 'love', 'the', 'boy', '.', '</s>']\n",
      "0.2222222222222222 - ['<s>', 'I', 'love', 'the', 'dog', '.', '</s>']\n",
      "0.1111111111111111 - ['<s>', 'They', 'love', 'the', 'dog', '.', '</s>']\n",
      "0.1111111111111111 - ['<s>', 'They', 'talk', 'to', 'the', 'girl', '.', '</s>']\n",
      "0.1111111111111111 - ['<s>', 'They', 'talk', 'to', 'the', 'dog', '.', '</s>']\n",
      "0.05555555555555555 - ['<s>', 'I', 'talk', 'to', 'the', 'mother', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "def get_trigrams(corpus):\n",
    "    '''Extract trigrams from corpus.'''\n",
    "    trigrams = []\n",
    "    for line in corpus:\n",
    "        line = line.split()\n",
    "        for i in range(len(line)-2):\n",
    "            trigrams.append(line[i:i+3])\n",
    "    return trigrams\n",
    "\n",
    "def trigram_prob(trigram_count_dict, bigram_count_dict):\n",
    "    '''Calcualte trigram probabilities.'''\n",
    "    trigram_prob_dict = defaultdict(float)\n",
    "    for trigram, count in trigram_count_dict.items():\n",
    "        trigram_prob = count / bigram_count_dict[trigram[:2]]\n",
    "        trigram_prob_dict[trigram] = trigram_prob\n",
    "    return trigram_prob_dict\n",
    "\n",
    "trigrams = get_trigrams(corpus_mod)\n",
    "trigram_count_dict = ngram_count(trigrams)\n",
    "trigram_prob_dict = trigram_prob(trigram_count_dict, bigram_count_dict)\n",
    "\n",
    "for line in corpus_mod:\n",
    "    line_split = line.split()\n",
    "    # Start with the bigram probability to deal with the  first word and the starting token p(word1 | <s>)\n",
    "    line_probs = [bigram_prob_dict[tuple(line_split[0:2])]]\n",
    "    for i in range(len(line_split)-2):\n",
    "        line_probs.append(trigram_prob_dict[tuple(line_split[i:i+3])])\n",
    "    print(f'{np.prod(line_probs)} - {line_split}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
